{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3e5ebc-8f6c-4bd0-ab2c-172dfe1a0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazendo a instaçação de pacotes que precisamos para importar os bancos do postgres e passar pro mongo e pro cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05211dc7-85ef-4377-8a13-ee0be4194bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in /opt/conda/lib/python3.10/site-packages (3.25.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from cassandra-driver) (1.16.0)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /opt/conda/lib/python3.10/site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.3)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.10/site-packages (1.4.37)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy) (1.1.2)\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.10/site-packages (4.1.1)\n",
      "Requirement already satisfied: psycopg2-binary in /opt/conda/lib/python3.10/site-packages (2.9.3)\n",
      "Requirement already satisfied: pymongo[srv] in /opt/conda/lib/python3.10/site-packages (4.1.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from pymongo[srv]) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install cassandra-driver\n",
    "! pip install SQLAlchemy\n",
    "! pip install pymongo\n",
    "! pip install psycopg2-binary\n",
    "! python -m pip install \"pymongo[srv]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18300d6-79fb-474a-b978-fcd12726a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.21.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#instalando pacotes para manipulaçao de dados\n",
    "! pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade1132c-3c13-40f4-8aec-c67f90653a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando todas as bibliotecas que precisamos usar nessa atividade:\n",
    "from cassandra.cluster import Cluster\n",
    "from pymongo import MongoClient\n",
    "from pymongo import InsertOne, DeleteOne, ReplaceOne\n",
    "from functools import reduce\n",
    "import psycopg2\n",
    "import pymongo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107207d-6ba5-41ab-8ebb-a822b6b11d76",
   "metadata": {},
   "source": [
    "## Conectando nos 3 bancos e criando suas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961ecd52-afe5-4f48-939e-eb9905a8efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postgres\n",
    "con = psycopg2.connect(host='dindin_pgdatabase', database='user',\n",
    "user='user', password='admin')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "737f2c02-6b6e-457b-8ff4-f7c97926ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cassandra\n",
    "cluster = Cluster([('dindin_cassandra','9042')])\n",
    "session = cluster.connect()\n",
    "session.default_timeout = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c55b16b1-495d-42f3-871f-feb291ec72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB\n",
    "# CONNECTION_STRING = \"mongodb+srv://root_dindin:admin@dindin_mongo.mongodb.net/dindin_agora?retryWrites=true&w=majority\"\n",
    "# CONNECTION_STRING = \"dindin_mongo:8081\"\n",
    "CONNECTION_STRING = \"mongodb://root_dindin:admin@mongo:27017/\"\n",
    "client = MongoClient(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501845b6-a415-473d-bc0d-766591d20716",
   "metadata": {},
   "source": [
    "## Consultando tabelas que estão no Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c26e41-9ff2-44a1-8b17-5801583bdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('select * from dindinagora.cliente')\n",
    "recset = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b07fb49-1f7a-4f7d-b4dc-27bc8af8d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'João Miguel  Queirós Aparecido', '715120359', '00.930.834.9-84', 69)\n",
      "(2, 'Maria Julia  Brasil  Barros', '687075338', '11.464.906.1-05', 67)\n",
      "(3, 'Theo  Magalhães   Barros', '579802040', '66.279.889.1-42', 28)\n",
      "(4, 'Marcela  Costa Calado', '519537378', '22.029.821.1-05', 141)\n",
      "(5, 'Vanessa  Fontes  Rodrigues', '142555651', '57.444.588.8-55', 79)\n"
     ]
    }
   ],
   "source": [
    "#trazendo as primeiras 5 linhas\n",
    "for rec in recset[0:5]:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bb6041-08c6-46e1-bfd0-bf7aea36c397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'nome', 'RG', 'CPF', 'endereco_fk']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizando as colunas\n",
    "[desc[0] for desc in cur.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec495c-d220-44e8-b777-d99ecd5393e1",
   "metadata": {},
   "source": [
    "## Caso de teste\n",
    "Neste cenário podemos simular requisições de uma plataforma através do JupyterNotebook, fazendo 2 cenários:\n",
    "\n",
    "1. Fazer 5000 requisições de tipos de empréstimo no Postgres\n",
    "\n",
    "2. Fazer uma requisição que lê o volume de transações, depósitos e empréstimos por dia dentro das bases transacionais\n",
    "\n",
    "Para ambas requisições, podemos gravar o tempo que levou para realizar estes cenários simulados para a pergunta 1 e 2 do enunciado.\n",
    "\n",
    "Assim sendo, verificamos os cenários primeiramente no Postgres, e posteriormente, transferimos os datasets necessários para os bancos que respectivamente seriam mais eficientes (MongoDB e Cassandra) e verificamos a eficiência de tempos de processamento desses em cada cenário. Para isso, geramos um índice aleatório que pode ser replicado em todos os cenários (para o caso 1).\n",
    "\n",
    "Obs: Em todos os casos, eu não armazeno todos os resultados por conta da atividade ter somente a necessidade de cronometrar o tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1f90f3-36ff-44de-adba-b0c469d687a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando índice aleatório\n",
    "random.seed(1994)\n",
    "cur_emp = con.cursor()\n",
    "cur_emp.execute('select * from dindinagora.dim_emprestimo;')\n",
    "recset_emp = cur_emp.fetchall()\n",
    "index_geral_emprestimos = [idd[0] for idd in recset_emp]\n",
    "rand_index = random.choices(index_geral_emprestimos, k=5000)\n",
    "#puxando os nomes da coluna dos tipos de emprestimo\n",
    "nomes_colunas_emp = [desc[0] for desc in cur_emp.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cfe885-762f-4623-8fd8-d4cbdcefdc4f",
   "metadata": {},
   "source": [
    "### Cenário 1: Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cf783b3-d313-4155-98da-5eaf79bde821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select * from dindinagora.dim_emprestimo where id = 36;\n"
     ]
    }
   ],
   "source": [
    "print(\"select * from dindinagora.dim_emprestimo where id = {0};\".format(36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5f90b2-9599-4141-9144-1dfc997747f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 322, 'montante': 2200.0, 'taxa_aa': 0.35, 'parcelas': 18},\n",
       " {'id': 354, 'montante': 5400.0, 'taxa_aa': 0.35, 'parcelas': 18},\n",
       " {'id': 187, 'montante': 8700.0, 'taxa_aa': 0.17, 'parcelas': 6},\n",
       " {'id': 79, 'montante': 7900.0, 'taxa_aa': 0.12, 'parcelas': 2}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur = con.cursor()\n",
    "start_time = time.time()\n",
    "val_emprestimos_postgres=[]\n",
    "\n",
    "for idx in rand_index:\n",
    "    cur.execute(\"select * from dindinagora.dim_emprestimo where id = {0};\".format(idx))\n",
    "    val_emprestimos_postgres.append(dict(zip(tuple(nomes_colunas_emp),cur.fetchall()[0])))    \n",
    "tp_1_postgres = (time.time() - start_time)\n",
    "#imprimindo os 5 primeiros registros\n",
    "val_emprestimos_postgres[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd0b39d-1f1d-44a3-8a18-64afc76da031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5434505939483643"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tempo para o postgres fazer as \"requisições\"\n",
    "tp_1_postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113584a-9dfb-4eb2-92f3-ba0d0eee46f9",
   "metadata": {},
   "source": [
    "### Cenário 2: Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed885966-8a7e-4232-99bc-f31b6aaa223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()\n",
    "start_time = time.time()\n",
    "\n",
    "cur.execute (\"\"\" select coalesce(coalesce(data_transferencia,data_deposito),data_emprestimo) as data\n",
    "                ,a.sum_transferencia\n",
    "                ,b.sum_deposito\n",
    "                ,c.sum_emprestimos\n",
    "                from\n",
    "                (\n",
    "                    select date(data_hora_transacao) as data_transferencia\n",
    "                           ,sum(montante) as sum_transferencia\n",
    "                    from dindinagora.tr_transferencia a\n",
    "                    group by date(data_hora_transacao)\n",
    "                ) a\n",
    "                full join\n",
    "                (\n",
    "                    select date(data_hora_transacao) as data_deposito\n",
    "                           ,sum(montante) as sum_deposito\n",
    "                    from dindinagora.tr_deposito a\n",
    "                    group by date(data_hora_transacao)\n",
    "                ) b\n",
    "                on a.data_transferencia = b.data_deposito\n",
    "                full join\n",
    "                (\n",
    "                    select date(a.data_hora_emprestimo) as data_emprestimo\n",
    "                           ,sum(b.montante) as sum_emprestimos\n",
    "                    from dindinagora.tr_emprestimo a\n",
    "                    left join dindinagora.dim_emprestimo b\n",
    "                    on a.emprestimo_fk = b.id\n",
    "                    group by date(data_hora_emprestimo)\n",
    "                ) c\n",
    "                on a.data_transferencia = c.data_emprestimo\n",
    "            \"\"\")\n",
    "\n",
    "result_post = cur.fetchall()\n",
    "tp_2_postgres = (time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7481a8be-7d6d-45a6-a8a2-359e7dfcfc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4607887268066406"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_2_postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa77e0-ceed-4987-ada8-5816e4b940e4",
   "metadata": {},
   "source": [
    "Agora, importamos os dados de tipos de empréstimos no MongoDB e empréstimos, depósitos e transferências no cassandra: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f27a9-3fb4-4298-853b-2459ff11da4c",
   "metadata": {},
   "source": [
    "### Para o MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8830e19-b40b-4359-b059-1576308bb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando coleção (para colocar dentro os json)\n",
    "mydb = client['dindin_agora']\n",
    "emprestimos=mydb['emprestimos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87fd70ff-8147-4381-b5df-ccc22696dc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'montante': 100.0, 'taxa_aa': 0.12, 'parcelas': 2}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#puxando os nomes da coluna dos tipos de emprestimo\n",
    "dict(zip(tuple(nomes_colunas_emp),recset_emp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "775c10e3-5753-4711-a719-d01b8871365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazendo para cada linha um dict que ira ser importado na colecao de emprestimos:\n",
    "lista_requests = []\n",
    "for i in range(0,max(index_geral_emprestimos)):\n",
    "    t = dict(zip(tuple(nomes_colunas_emp),recset_emp[i]))\n",
    "    lista_requests.append(InsertOne(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b17644ae-e4d1-4b3f-821f-97521acdca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = emprestimos.bulk_write(lista_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "008db12b-3deb-4280-8a3b-e705a438a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando se foi gravado mesmo\n",
    "result.inserted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b913e49-7055-4c3e-b761-5833d6e1b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 322, 'montante': 2200.0, 'taxa_aa': 0.35, 'parcelas': 18},\n",
       " {'id': 354, 'montante': 5400.0, 'taxa_aa': 0.35, 'parcelas': 18},\n",
       " {'id': 187, 'montante': 8700.0, 'taxa_aa': 0.17, 'parcelas': 6},\n",
       " {'id': 79, 'montante': 7900.0, 'taxa_aa': 0.12, 'parcelas': 2}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agora testamos a consulta dos 5000 registros pelo mongodb:\n",
    "start_time = time.time()\n",
    "val_emprestimos_mongodb=[]\n",
    "for idx in rand_index:\n",
    "    doc = dict(emprestimos.find_one({'id':idx}))\n",
    "    doc.pop('_id')\n",
    "    val_emprestimos_mongodb.append(doc)\n",
    "tp_1_mongodb = (time.time() - start_time)\n",
    "#verificand as 5 primeiras linhas\n",
    "val_emprestimos_mongodb[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df31a019-1c14-405b-b78d-bb87072c8e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.858848810195923"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_1_mongodb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7624ff2-18ba-41b0-b527-6355d744ab29",
   "metadata": {},
   "source": [
    "### Fazendo agora para o Cassandra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ff70d9-e67b-4dcd-ae60-86771e5c0c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f2e15a82b00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Para importar os dados transacionais, temos 3 datasets diferentes que podemos colocar dentro\n",
    "#do mesmo keyspace (dindin_agora):\n",
    "\n",
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS dindin_agora \n",
    "    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'} \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3457ef80-4387-47b6-9f90-e1793f1b4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gravando o schema das atbelas usadas num dict (só pra facilitar)\n",
    "tabelas= {'tr_transferencia':{'id':'int','montante':'float','tipo':'text','data_hora_transacao':'timestamp','origem_fk':'int','destino_fk':'int'}\n",
    "          ,'tr_deposito':{'id':'int','montante':'float','conta_fk':'int','data_hora_transacao':'timestamp'}\n",
    "          ,'tr_emprestimo':{'id':'int','conta_fk':'int','emprestimo_fk':'int','data_hora_emprestimo':'timestamp'}\n",
    "          ,'dim_emprestimo':{'id':'int','montante':'float','taxa_aa':'float','parcelas':'int'}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "735a24f7-037f-45e9-a206-0264eebd2333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " para tr_transferencia\n",
      "\n",
      " para tr_deposito\n",
      "\n",
      " para tr_emprestimo\n",
      "\n",
      " para dim_emprestimo\n"
     ]
    }
   ],
   "source": [
    "#criando tabelas para fazer a importação depois (do schema do postgres)\n",
    "session.set_keyspace(\"dindin_agora\")\n",
    "for indx in tabelas:\n",
    "    \n",
    "    print('\\n para '+indx)\n",
    "    \n",
    "    dic = tabelas.get(indx)\n",
    "    lista_vals = []\n",
    "    for elmt in dic:\n",
    "        lista_vals.append(elmt+' '+dic.get(elmt)+',')\n",
    "\n",
    "    string_colunas_tip = reduce(lambda x, y: x + y, lista_vals)\n",
    "    string_colunas = reduce(lambda x, y: x +','+ y, dic)\n",
    "    string_imput = reduce(lambda x,y: x+','+y,['?' for i in range(0,len(dic))])\n",
    "\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS {0} (\".format(indx)+string_colunas_tip+\" PRIMARY KEY(id))\")\n",
    "    prepared = session.prepare(\"INSERT INTO {0} (\".format(indx)+string_colunas+\") VALUES (\"+string_imput+\")\")\n",
    "\n",
    "    cur = con.cursor()\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"select * from dindinagora.{0}\".format(indx))\n",
    "    linhas_import = cur.fetchall()\n",
    "\n",
    "    #laço que le linha a linha da tabela selecionada:\n",
    "    for linn in linhas_import:\n",
    "        session.execute(prepared, linn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "416433c7-5f56-4c2a-95b3-52550bd3e2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=4317, data_hora_transacao=datetime.datetime(2022, 3, 24, 17, 44, 20), destino_fk=538, montante=459.3399963378906, origem_fk=814, tipo='DOC')\n",
      "Row(id=3372, data_hora_transacao=datetime.datetime(2022, 4, 22, 22, 14, 48), destino_fk=305, montante=103.48999786376953, origem_fk=659, tipo='DOC')\n",
      "Row(id=1584, data_hora_transacao=datetime.datetime(2021, 10, 31, 16, 3, 46), destino_fk=421, montante=61.619998931884766, origem_fk=19, tipo='TED')\n",
      "Row(id=4830, data_hora_transacao=datetime.datetime(2021, 5, 30, 3, 6, 18), destino_fk=112, montante=388.4100036621094, origem_fk=392, tipo='DOC')\n",
      "Row(id=2731, data_hora_transacao=datetime.datetime(2021, 2, 7, 13, 27, 47), destino_fk=512, montante=143.72000122070312, origem_fk=847, tipo='PIX')\n",
      "----------------\n",
      "Row(id=23, conta_fk=852, data_hora_transacao=datetime.datetime(2022, 1, 18, 21, 40, 32), montante=474.1775817871094)\n",
      "Row(id=114, conta_fk=558, data_hora_transacao=datetime.datetime(2021, 5, 1, 6, 12, 58), montante=582.2879638671875)\n",
      "Row(id=53, conta_fk=195, data_hora_transacao=datetime.datetime(2021, 9, 25, 4, 44, 32), montante=210.7241668701172)\n",
      "Row(id=110, conta_fk=199, data_hora_transacao=datetime.datetime(2021, 3, 19, 21, 40, 15), montante=500.5715026855469)\n",
      "Row(id=91, conta_fk=790, data_hora_transacao=datetime.datetime(2022, 1, 11, 22, 38, 36), montante=291.0373840332031)\n",
      "----------------\n",
      "Row(id=23, conta_fk=432, data_hora_emprestimo=datetime.datetime(2022, 4, 2, 2, 46, 27), emprestimo_fk=232)\n",
      "Row(id=53, conta_fk=339, data_hora_emprestimo=datetime.datetime(2021, 9, 18, 1, 53, 45), emprestimo_fk=1)\n",
      "Row(id=91, conta_fk=163, data_hora_emprestimo=datetime.datetime(2021, 11, 2, 10, 43, 6), emprestimo_fk=348)\n",
      "Row(id=55, conta_fk=737, data_hora_emprestimo=datetime.datetime(2021, 7, 19, 8, 41), emprestimo_fk=420)\n",
      "Row(id=33, conta_fk=439, data_hora_emprestimo=datetime.datetime(2022, 1, 19, 12, 24, 22), emprestimo_fk=246)\n",
      "----------------\n",
      "Row(id=23, montante=2300.0, parcelas=2, taxa_aa=0.11999999731779099)\n",
      "Row(id=114, montante=1400.0, parcelas=6, taxa_aa=0.17000000178813934)\n",
      "Row(id=53, montante=5300.0, parcelas=2, taxa_aa=0.11999999731779099)\n",
      "Row(id=110, montante=1000.0, parcelas=6, taxa_aa=0.17000000178813934)\n",
      "Row(id=91, montante=9100.0, parcelas=2, taxa_aa=0.11999999731779099)\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "#verificando as primeiras 10 linhas por tabela:\n",
    "for indx in tabelas:\n",
    "    result = session.execute(\"select * from {0} \".format(indx)+\"limit 5\")\n",
    "    for ress in result:\n",
    "        print(ress)\n",
    "    print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f151b391-6942-49f9-ab85-a6a7ac7b9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, fazendo a consulta completa dos valores de série temporal:\n",
    "# Como o cassandra não suporta joins, temos que puxar tudo para o python e trabalhar com data \n",
    "# frames aqui:\n",
    "session.set_keyspace(\"dindin_agora\")\n",
    "start_time = time.time()\n",
    "\n",
    "lista_transf =[]\n",
    "result = session.execute(\"\"\"\n",
    "                            select montante,data_hora_transacao\n",
    "                            from tr_transferencia\n",
    "                         \"\"\")\n",
    "    \n",
    "for ress in result:\n",
    "    lista_transf.append(tuple(ress))\n",
    "\n",
    "#para depósitos\n",
    "lista_depositos =[]\n",
    "result = session.execute(\"\"\"\n",
    "                            select montante,data_hora_transacao\n",
    "                            from tr_deposito\n",
    "                         \"\"\")\n",
    "    \n",
    "for ress in result:\n",
    "    lista_depositos.append(tuple(ress))\n",
    "\n",
    "#para emprestimos\n",
    "lista_emprestimos =[]\n",
    "result = session.execute(\"\"\"\n",
    "                            select emprestimo_fk,data_hora_emprestimo\n",
    "                            from tr_emprestimo\n",
    "                         \"\"\")\n",
    "    \n",
    "for ress in result:\n",
    "    lista_emprestimos.append(tuple(ress))\n",
    "    \n",
    "#para emprestimos\n",
    "lista_dim_emprestimos =[]\n",
    "result = session.execute(\"\"\"\n",
    "                            select id,montante\n",
    "                            from dim_emprestimo\n",
    "                         \"\"\")\n",
    "    \n",
    "for ress in result:\n",
    "    lista_dim_emprestimos.append(tuple(ress))\n",
    "\n",
    "time_cassandra_1 = time.time()\n",
    "\n",
    "df_dim_emprestimos = pd.DataFrame(lista_dim_emprestimos)\n",
    "df_dim_emprestimos.columns =['id','montante_emp']\n",
    "\n",
    "df_emprestimos = pd.DataFrame(lista_emprestimos)\n",
    "df_emprestimos.columns =['emprestimo_fk','data_hora_emprestimo']\n",
    "\n",
    "df_depositos = pd.DataFrame(lista_depositos)\n",
    "df_depositos.columns =['montante_dep','data_hora_transacao']\n",
    "\n",
    "df_transf = pd.DataFrame(lista_transf)\n",
    "df_transf.columns =['montante_trsf','data_hora_transacao']\n",
    "\n",
    "# Fazendo as agregações que precisa antes do merge (ou join)\n",
    "#criando uma coluna de data:\n",
    "df_depositos['data_transacao'] = df_depositos['data_hora_transacao'].apply(lambda x: x.date())\n",
    "df_transf['data_transacao'] = df_transf['data_hora_transacao'].apply(lambda x: x.date())\n",
    "df_emprestimos['data_emprestimo'] = df_emprestimos['data_hora_emprestimo'].apply(lambda x: x.date())\n",
    "\n",
    "#agora realizando o agrupamento por dia e fazendo os joins\n",
    "df_depositos_g = df_depositos.groupby('data_transacao',as_index=False)['montante_dep'].sum()\n",
    "df_transf_g = df_transf.groupby('data_transacao',as_index=False)['montante_trsf'].sum()\n",
    "\n",
    "#e para a de emprestimos:\n",
    "df_emprestimos_g = pd.merge(df_emprestimos\n",
    "        ,df_dim_emprestimos\n",
    "        ,left_on= ['emprestimo_fk']\n",
    "        ,right_on= ['id'] \n",
    "         ,how = 'left').groupby('data_emprestimo',as_index=False)['montante_emp'].sum()\n",
    "\n",
    "#e por fim juntando tudo num df:\n",
    "df_cruz = pd.merge(df_depositos_g,df_transf_g,on= 'data_transacao',how='outer').merge(df_emprestimos_g\n",
    "                                                                                      ,left_on='data_transacao'\n",
    "                                                                                      ,right_on = 'data_emprestimo',how='outer')\n",
    "df_cruz['data_transacao']=df_cruz[['data_transacao','data_emprestimo']].bfill(axis=1).iloc[:, 0]\n",
    "df_cruz.drop(['data_emprestimo'],axis=1,inplace=True)\n",
    "time_cassandra_2 = time.time()\n",
    "\n",
    "#agora usando pandas para fazer as agregações dentro do jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a405aefc-3f0b-4122-9383-0e6f92b35b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_transacao</th>\n",
       "      <th>montante_dep</th>\n",
       "      <th>montante_trsf</th>\n",
       "      <th>montante_emp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>300.361237</td>\n",
       "      <td>10218.060028</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>519.614990</td>\n",
       "      <td>3158.029996</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>632.922546</td>\n",
       "      <td>5870.800079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>311.113983</td>\n",
       "      <td>1449.199978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-09</td>\n",
       "      <td>201.752380</td>\n",
       "      <td>5598.689995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3116.699970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6487.669968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1718.989967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5135.519938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3753.879993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_transacao  montante_dep  montante_trsf  montante_emp\n",
       "0       2021-01-02    300.361237   10218.060028        7700.0\n",
       "1       2021-01-03    519.614990    3158.029996           NaN\n",
       "2       2021-01-04    632.922546    5870.800079           NaN\n",
       "3       2021-01-07    311.113983    1449.199978           NaN\n",
       "4       2021-01-09    201.752380    5598.689995           NaN\n",
       "..             ...           ...            ...           ...\n",
       "511     2022-05-23           NaN    3116.699970           NaN\n",
       "512     2022-05-25           NaN    6487.669968           NaN\n",
       "513     2022-05-29           NaN    1718.989967           NaN\n",
       "514     2022-05-30           NaN    5135.519938           NaN\n",
       "515     2022-05-31           NaN    3753.879993           NaN\n",
       "\n",
       "[516 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16551aee-92af-4dad-af87-9687d9a57ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cur.close()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07b861-e633-4a4a-8262-66d55b4f5fdb",
   "metadata": {},
   "source": [
    "Agora analisando os tempos que obtivemos para cada situação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1fbd9d0-a3d5-4910-a710-0302b37ade15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo para situação 1 com Postgres:2.5435\n",
      "Tempo para situação 2 com Postgres:1.4608\n",
      "Tempo para situação 1 com MongoDb:8.8588\n",
      "Tempo para situação 2 com Cassandra (só o fetch):0.8213\n",
      "Tempo para situação 2 após consultar Cassandra e manipulação com pandas:0.2674\n",
      "Tempo para situação 2 com Cassandra total:1.0887\n"
     ]
    }
   ],
   "source": [
    "print('Tempo para situação 1 com Postgres:{:3.4f}'.format(tp_1_postgres))  \n",
    "print('Tempo para situação 2 com Postgres:{:3.4f}'.format(tp_2_postgres))\n",
    "print('Tempo para situação 1 com MongoDb:{:3.4f}'.format(tp_1_mongodb))\n",
    "print('Tempo para situação 2 com Cassandra (só o fetch):{:3.4f}'.format(time_cassandra_1-start_time))\n",
    "print('Tempo para situação 2 após consultar Cassandra e manipulação com pandas:{:3.4f}'.format(time_cassandra_2-time_cassandra_1))\n",
    "print('Tempo para situação 2 com Cassandra total:{:3.4f}'.format(time_cassandra_2-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880c7a0-f31d-464e-ac2b-d564839ad988",
   "metadata": {},
   "source": [
    "Por algum motivo as soluções que escolhemos performou um pouco mais devagar comparado com o postgres, mas provavelmente é por conta do dataset ser pequeno e, não estarmos considerando um cenário em que tivesse muitas requisições de vários clientes. Isso mostra que essa simulação poderia ser aprimorada para um cenário mais real se tivessemos trabalhado com um paralelismo sobre as requisições, mostrando que em um workload pesado os bancos do MongoDB e do Cassandra sairiam melhor. Em particular, o Cassandra foi mais rápido na consulta do que o Postgres, mesmo considerando o tempo total de manipulação com os dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431b5a1-9e56-41ab-834c-3b52e200db3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
